on_IN tree_NN -RRB-_-RRB- 。_FW VFDT_FW 能用_FW 固定的内存和固定的时间为每个用例构建一棵决策树_FW 。_FW 它利用_FW Hoeffding_FW 边界来保证算法的输出模型与批量_FW 学习_NN -LRB-_-LRB- batch_NN learner_NN -RRB-_-RRB- 的输出模型是趋向于一致的_FW 。_FW 然而_NN ,_, 一个流数据的模型并不是一成不变的_NN ,_, 它会随时间而变化_NN ,_, 但这个算法对整个数据流只用一种模_NNP 型来表示_NNP ,_, 所以模型精确度是很差的_NNP 。_NNP 我们需要的是一个随数据流的变化_NNP ,_, 能生成不同模型的算法_NNP 。_NNP Wang_NNP 等人在_NN =_JJ -_: =[_NN 7_CD -RRB-_-RRB- -_: =_JJ -_: 中给出了一个处理数据流中概念递移的方法_NN --_: --_: 加权分类器聚集_CD -LRB-_-LRB- weighted_JJ classifier_NN ensembles_NNS -RRB-_-RRB- 。_NNP 现在_NNP ,_, 我们不需要不断的修改一个单一的模型_NNP ,_, 而可以在流的连续数据块中设置多个分类器来采集模型_NNP 。_NNP 我们也不需要维持一个最新的分类器_NNP ,_, 因为一些潜在有用的信息可能就在以前使用过的因不够精确而被丢弃_NNP 的分类器的模型中_NNP 。_NNP 为了防止对数据的描述过于细致以及概念冲突等问题_NNP ,_, 数据是否过期由数据的分_NN
