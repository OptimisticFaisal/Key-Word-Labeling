ine_NN learning_NN algorithms_NNS process_VBP each_DT training_NN example_NN once_RB ``_`` on_IN arrival_NN ''_'' ,_, without_IN the_DT need_NN for_IN storage_NN or_CC reprocessing_NN ,_, and_CC maintain_VB a_DT current_JJ hypothesis_NN that_WDT reflects_VBZ all_PDT the_DT training_NN examples_NNS so_RB far_RB =_JJ -_: =[_NN 1_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN this_DT way_NN ,_, the_DT learning_NN algorithms_NNS take_VBP as_IN input_NN a_DT single_JJ training_NN example_NN as_RB well_RB as_IN a_DT hypothesis_NN and_CC output_NN an_DT updated_VBN hypothesis_NN -LRB-_-LRB- 2_CD -RRB-_-RRB- ._.
We_PRP consider_VBP on-line_JJ learning_NN as_IN a_DT particular_JJ case_NN of_IN increm_NN
