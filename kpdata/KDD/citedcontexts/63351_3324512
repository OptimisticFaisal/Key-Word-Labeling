e_LS the_DT references_NNS provided_VBN in_IN Section_NN 1_CD -RRB-_-RRB- ,_, approaches_NNS that_WDT rely_VBP on_IN a_DT combination_NN of_IN planning_NN and_CC learning_NN -LRB-_-LRB- e.g._FW ,_, -LRB-_-LRB- 29_CD ,_, 30_CD ,_, 38_CD -RRB-_-RRB- -RRB-_-RRB- ,_, and_CC approaches_NNS that_WDT rely_VBP on_IN a_DT combination_NN of_IN reacting_VBG and_CC learning_VBG -LRB-_-LRB- e.g._FW ,_, =_JJ -_: =[_NN 3_CD ,_, 17_CD ,_, 19_CD ,_, 21_CD ,_, 26_CD ,_, 24_CD ,_, 36_CD ,_, 37_CD -RRB-_-RRB- -RRB-_-RRB- ._.
M_NN -_: =_JJ --_: Dyna-Q_NN can_MD be_VB considered_VBN as_IN a_DT generalization_NN of_IN these_DT approaches_NNS ,_, and_CC as_IN such_JJ it_PRP aims_VBZ at_IN offering_VBG ``_`` maximum_JJ coordination_NN flexibility_NN ._. ''_''
This_DT is_VBZ not_RB to_TO say_VB that_DT M-DynaQ_NN is_VBZ the_DT best_JJS choice_NN for_IN every_DT
