oitation_NN of_IN massive_JJ real-world_JJ data_NNS for_IN finding_VBG ``_`` valid_JJ ,_, new_JJ and_CC useful_JJ ''_'' regularities_NNS -LRB-_-LRB- 33_CD ,_, 49_CD ,_, 50_CD -RRB-_-RRB- ._.
While_IN significant_JJ advances_NNS have_VBP been_VBN made_VBN for_IN specific_JJ DM_NN tasks_NNS ,_, e.g._FW identifying_VBG frequent_JJ item_NN sets_VBZ =_JJ -_: =[_NN 56_CD ,_, 139_CD ,_, 17_CD ,_, 128_CD -RRB-_-RRB- -_: =_JJ -_: ,_, the_DT DM_NN process_NN suffers_VBZ from_IN three_CD bottlenecks_NNS ._.
Firstly_RB ,_, it_PRP is_VBZ widely_RB acknowledged_VBN that_IN 80_CD %_NN of_IN the_DT DM_NN effort_NN is_VBZ spent_VBN in_IN the_DT pre-processing_JJ step_NN -LRB-_-LRB- cleaning_NN ,_, selecting_NN ,_, merging_JJ ,_, etc_NN ,_, the_DT datasets_NNS -RRB-_-RRB- ._.
Thi_NNP
