s_NN ,_, weighted_JJ error_NN rate_NN of_IN the_DT weak_JJ learners_NNS of_IN at_IN most_JJS 1\/2_CD −_FW λ_FW for_IN each_DT iteration_NN --_: then_RB the_DT training_NN margins_NNS will_MD increase_VB ,_, and_CC generalization_NN error_NN will_MD go_VB to_TO 0_CD for_IN large_JJ enough_JJ training_NN samples_NNS -LRB-_-LRB- see_VB =_JJ -_: =[_NN 20_CD -RRB-_-RRB- -_: =_SYM -_: for_IN more_JJR details_NNS -RRB-_-RRB- ._.
Duffy_NN and_CC Helmbold_NN -LRB-_-LRB- -LRB-_-LRB- 7_CD -RRB-_-RRB- ,_, Theorems_NNPS 24_CD -RRB-_-RRB- give_VBP sufficient_JJ conditions_NNS for_IN this_DT property_NN to_TO hold_VB ,_, which_WDT apply_VBP to_TO the_DT exponential_JJ and_CC logistic_JJ loss_NN functions_NNS ._.
These_DT conditions_NNS include_VBP str_NN
