d_NN via_IN methods_NNS such_JJ as_IN LBFGS_NN -LRB-_-LRB- 21_CD -RRB-_-RRB- ;_: however_RB ,_, for_IN very_RB large_JJ data_NNS sets_NNS ,_, these_DT methods_NNS do_VBP not_RB scale_VB well_RB due_JJ to_TO large_JJ matrix_NN manipulations_NNS ._.
We_PRP thus_RB use_VBP stochastic_JJ gradient_NN descent_NN as_IN a_DT viable_JJ alternative_NN =_JJ -_: =[_NN 19_CD -RRB-_-RRB- -_: =_JJ -_: ,_, noting_VBG that_IN the_DT non-differentiability_NN induced_VBN by_IN the_DT L1_NN penalty_NN term_NN can_MD be_VB handled_VBN by_IN methods_NNS similar_JJ to_TO truncated_VBN gradient_NN descent_NN -LRB-_-LRB- 20_CD -RRB-_-RRB- ._.
To_TO achieve_VB scalability_NN ,_, we_PRP use_VBP a_DT parallelized_JJ learning_NN algo_NN
