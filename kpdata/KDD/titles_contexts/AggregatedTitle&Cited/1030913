A_DT theoretical_JJ framework_NN for_IN learning_VBG from_IN a_DT pool_NN of_IN disparate_JJ data_NNS sources_NNS
y_NN that_WDT have_VBP been_VBN successfully_RB applied_VBN to_TO sensor_NN fusion_NN problems_NNS -LRB-_-LRB- 9_CD -RRB-_-RRB- ._.
Moreover_RB ,_, we_PRP hope_VBP to_TO use_VB recent_JJ work_NN examining_VBG the_DT mathematics_NN underlying_VBG the_DT complexities_NNS of_IN learning_VBG from_IN disparate_JJ data_NNS sources_NNS =_JJ -_: =[_NN 12_CD -RRB-_-RRB- -_: =_SYM -_: to_TO develop_VB new_JJ methods_NNS ._.
In_IN applying_VBG our_PRP$ theoretical_JJ framework_NN to_TO a_DT real_JJ problem_NN ,_, we_PRP learned_VBD many_JJ lessons_NNS about_IN the_DT generalities_NNS that_WDT exist_VBP in_IN our_PRP$ framework_NN ._.
For_IN example_NN ,_, two_CD of_IN the_DT three_CD base_NN classif_NN
n_NN data_NNS integration_NN via_IN multitask_NNS learning_VBG where_WRB each_DT data_NNS source_NN has_VBZ the_DT same_JJ binary_JJ label_NN space_NN ,_, whereas_IN the_DT attributes_NNS of_IN the_DT inputs_NNS can_MD admit_VB different_JJ orderings_NNS as_RB well_RB as_IN be_VB linearly_RB transformed_VBN =_JJ -_: =[_NN 11_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT remainder_NN of_IN the_DT paper_NN is_VBZ organized_VBN as_IN follows_VBZ ._.
We_PRP briefly_RB develop_VBP background_NN on_IN the_DT maximum_NN entropy_NN estimation_NN problem_NN and_CC its_PRP$ dual_JJ in_IN Section_NN 2_CD ._.
We_PRP introduce_VBP in_IN Section_NN 3_CD the_DT novel_JJ multitask_FW f_FW
roblem_NN of_IN learning_VBG predictive_JJ models_NNS from_IN distributed_VBN data_NNS sources_NNS -LRB-_-LRB- 17_CD -RRB-_-RRB- -LRB-_-LRB- 18_CD -RRB-_-RRB- ._.
Crammer_NNP et_FW al._FW -LRB-_-LRB- 19_CD -RRB-_-RRB- have_VBP examined_VBN the_DT problem_NN of_IN learning_VBG predictors_NNS from_IN a_DT set_NN of_IN related_JJ data_NNS sources_NNS ._.
Ben-David_NNP et_FW al._FW =_SYM -_: =[_NN 20_CD -RRB-_-RRB- -_: =_SYM -_: have_VBP analyzed_VBN the_DT sample_NN complexity_NN of_IN learning_VBG from_IN semantically_RB disparate_JJ data_NN sources_NNS ._.
However_RB ,_, none_NN of_IN these_DT works_NNS have_VBP considered_VBN the_DT effect_NN of_IN errors_NNS in_IN mappings_NNS between_IN the_DT representations_NNS use_VBP
alization_NN and_CC benefit_VB all_DT of_IN the_DT tasks_NNS ._.
This_DT phenomenon_NN has_VBZ been_VBN examined_VBN further_RBR by_IN recent_JJ papers_NNS which_WDT have_VBP started_VBN to_TO build_VB a_DT theoretical_JJ foundation_NN that_WDT underpins_VBZ these_DT initial_JJ empirical_JJ findings_NNS =_JJ -_: =[_NN 1_CD ,_, 2_CD ,_, 3_CD -RRB-_-RRB- -_: =_SYM -_: ._.
A_DT well-known_JJ application_NN of_IN MTL_NN occurs_VBZ within_IN the_DT realm_NN of_IN speech_NN recognition_NN ._.
The_DT way_NN different_JJ people_NNS pronounce_VBP the_DT same_JJ words_NNS differs_VBZ greatly_RB based_VBN on_IN their_PRP$ gender_NN ,_, accent_NN ,_, nationality_NN or_CC other_JJ i_FW
s._NN On_IN the_DT other_JJ hand_NN ,_, there_EX are_VBP practical_JJ circumstances_NNS where_WRB the_DT output_NN data_NNS yiℓ_NN is_VBZ independent_JJ of_IN ℓ_NN ._.
For_IN example_NN ,_, this_DT occurs_VBZ in_IN the_DT problem_NN of_IN integrating_VBG information_NN from_IN heterogeneous_JJ databases_NNS -LRB-_-LRB- =_JJ -_: =_JJ Ben-David_NNP ,_, Gehrke_NNP ,_, and_CC Schuller_NNP ,_, 2002_CD -_: =--RRB-_NN ._.
In_IN other_JJ cases_NNS one_CD does_VBZ not_RB have_VB either_CC possibilities_NNS ,_, that_DT is_VBZ ,_, the_DT spaces_NNS Xℓ_FW ×_FW Yℓ_NN are_VBP different_JJ ._.
This_DT is_VBZ for_IN example_NN the_DT machine_NN vision_NN case_NN of_IN learning_VBG to_TO recognize_VB a_DT face_NN by_IN first_JJ learning_NN to_TO rec_NN
we_PRP see_VBP that_IN -LRB-_-LRB- h_NN ∗_NN -RRB-_-RRB- ∼_CD F_NN shatters_NNS S_NN ,_, so_IN m_NN ≤_FW VC-dim_FW -LRB-_-LRB- -LRB-_-LRB- h_NN ∗_NN -RRB-_-RRB- ∼_NN F_NN -RRB-_-RRB- ._.
M_NN To_TO eliminate_VB the_DT dependence_NN on_IN |_FW h0_FW |_NN =_JJ K_NN ,_, we_PRP set_VBD n0_NN =_JJ M\/2_FW −_FW 1_CD 2M_NN ,_, noting_VBG that_IN K_NNP n0_NNP ≥_NNP −_NNP 1_CD 2m_NN for_IN all_DT K_NN ,_, m_NN ≤_FW M._FW m_NN Ben-David_NNP ,_, et_NNP ._.
al._FW =_SYM -_: =[_NN 3_CD -RRB-_-RRB- -_: =_SYM -_: provide_VBP the_DT following_NN further_RB results_VBZ on_IN dH_FW ∼_FW F_NN -LRB-_-LRB- n_NN -RRB-_-RRB- ._.
Theorem_NN 4.2_CD If_IN F_NN is_VBZ finite_JJ and_CC n_NN log_NN -LRB-_-LRB- n_NN -RRB-_-RRB- ≥_FW VC-dim_FW -LRB-_-LRB- H_NN -RRB-_-RRB- ,_, then_RB dH_FW ∼_FW F_NN -LRB-_-LRB- n_NN -RRB-_-RRB- ≤_NN 2_CD log_NN -LRB-_-LRB- |_NN F_NN |_CD -RRB-_-RRB- Theorem_NNP 4.3_CD If_IN ∼_CD F_NN is_VBZ of_IN finite_JJ index_NN k_NN ,_, and_CC n_NN ≥_CD dH_NN ∼_NN F_NN -LRB-_-LRB- n_NN -RRB-_-RRB- ≤_CD log_NN k_NN
its_PRP$ of_IN such_JJ multi_NNS --_: task_NN learning_NN relative_JJ to_TO individual_JJ task_NN learning_VBG when_WRB tasks_NNS are_VBP related_JJ ,_, see_VB -LRB-_-LRB- 4_CD ,_, 11_CD ,_, 15_CD ,_, 22_CD -RRB-_-RRB- ._.
There_EX have_VBP also_RB been_VBN various_JJ attempts_NNS to_TO theoretically_RB study_VB multi_NNS --_: task_NN learning_NN ,_, see_VBP =_JJ -_: =[_NN 4_CD ,_, 5_CD ,_, 6_CD ,_, 7_CD ,_, 8_CD ,_, 15_CD ,_, 23_CD -RRB-_-RRB- -_: =_SYM -_: ._.
In_IN this_DT paper_NN we_PRP develop_VBP methods_NNS for_IN multi_NNS --_: task_NN learning_NN that_WDT are_VBP natural_JJ extensions_NNS of_IN existing_VBG kernel_NN based_VBN learning_VBG methods_NNS for_IN single_JJ task_NN learning_NN ,_, such_JJ as_IN Support_NN Vector_NNP Machines_NNP -LRB-_-LRB- SVMs_NNS -RRB-_-RRB- -LRB-_-LRB- 25_CD -RRB-_-RRB- ._.
d_NN now_RB require_VBP that_IN ˆ_NN P_NN -LRB-_-LRB- S_NN -RRB-_-RRB- be_VB a_DT good_JJ estimate_NN of_IN the_DT probability_NN P_NN -LRB-_-LRB- S_NN -RRB-_-RRB- for_IN a_DT randomly_RB drawn_VBN set_VBN from_IN the_DT class_NN T_NN ._.
This_DT corresponds_VBZ to_TO the_DT measure_NN between_IN distributions_NNS introduced_VBN by_IN Ben-David_NNP et_FW al._FW =_SYM -_: =[_NN 3_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Their_PRP$ results_NNS are_VBP an_DT important_JJ example_NN of_IN the_DT power_NN of_IN the_DT proposed_VBN approach_NN ._.
Example_NN 4_CD For_IN a_DT third_JJ example_NN consider_VBP a_DT distribution_NN over_IN -LCB-_-LRB- 0_CD ,_, 1_CD -RCB-_-RRB- n_NN ._.
The_DT touchstone_NN class_NN FI_NN is_VBZ taken_VBN as_IN a_DT set_NN of_IN `_`` proj_NN
-RRB-_-RRB- #F_NN shatters_NNS S_NN ,_, so_IN m_NN #_# VC-dim_JJ -LRB-_-LRB- -LRB-_-LRB- h_NN #_# -RRB-_-RRB- #F_NN -RRB-_-RRB- ._.
To_TO eliminate_VB the_DT dependence_NN on_IN |_CD h_NN 0_CD |_NN =_JJ K_NN ,_, we_PRP set_VBD n_NN 0_CD =_JJ #_# #_# M_NNP M\/2_NNP #_# -_: 1_CD #_# 2_CD M_NN ,_, noting_VBG that_IN n_NN 0_CD #_# #_# #_# K_NN m_NN #_# -_: 1_CD #_# 2_CD m_NN for_IN all_DT K_NN ,_, m_NN #_# M_NN ._.
Ben-David_NNP ,_, et_NNP ._.
al._FW =_SYM -_: =[_NN 3_CD -RRB-_-RRB- -_: =_SYM -_: provide_VBP the_DT following_NN further_RB results_VBZ on_IN dH_NN #_# F_NN -LRB-_-LRB- n_NN -RRB-_-RRB- ._.
Theorem_NN 4.2_CD If_IN F_NN is_VBZ finite_JJ and_CC n_NN log_NN -LRB-_-LRB- n_NN -RRB-_-RRB- #_# VC-dim_JJ -LRB-_-LRB- H_NN -RRB-_-RRB- ,_, then_RB dH_NN #_# F_NN -LRB-_-LRB- n_NN -RRB-_-RRB- #_# 2_CD log_NN -LRB-_-LRB- |_NN F_NN |_CD -RRB-_-RRB- Theorem_NNP 4.3_CD If_IN #F_NN is_VBZ of_IN finite_JJ index_NN k_NN ,_, and_CC n_NN #_# log_VB k_NN 4d_NN log_NN d_NN ,_,
