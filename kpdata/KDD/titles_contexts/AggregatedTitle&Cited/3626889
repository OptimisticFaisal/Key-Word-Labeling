A_DT Bayesian_JJ network_NN framework_NN for_IN reject_VB inference_NN
ng_NN algorithms_NNS could_MD or_CC could_MD not_RB be_VB affected_VBN by_IN feature_NN bias_NN ._.
This_DT all_DT depends_VBZ on_RP if_IN the_DT true_JJ model_NN is_VBZ contained_VBN in_IN the_DT model_NN space_NN of_IN the_DT learner_NN or_CC not_RB ,_, which_WDT is_VBZ generally_RB unknown_JJ ._.
Smith_NNP and_CC Elkan_NNP -LRB-_-LRB- =_JJ -_: =_JJ Smith_NNP and_CC Elkan_NNP ,_, 2004_CD -_: =-]_CD provide_VBP a_DT systematic_JJ characterization_NN of_IN the_DT different_JJ types_NNS of_IN sample_NN selection_NN bias_NN and_CC examples_NNS of_IN real-world_JJ situation_NN where_WRB they_PRP arise_VBP ._.
For_IN the_DT characterization_NN ,_, they_PRP use_VBP a_DT Bayesian_JJ network_NN rep_NN
sitive_JJ example_NN is_VBZ labeled_VBN ._.
This_DT ``_`` selected_VBN completely_RB at_IN random_JJ ''_'' assumption_NN is_VBZ analogous_JJ to_TO the_DT ``_`` missing_VBG completely_RB at_IN random_JJ ''_'' assumption_NN that_WDT is_VBZ often_RB made_VBN when_WRB learning_VBG from_IN data_NNS with_IN missing_VBG values_NNS =_JJ -_: =[_NN 10_CD ,_, 17_CD ,_, 18_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Another_DT way_NN of_IN stating_VBG the_DT assumption_NN is_VBZ that_IN s_NN and_CC x_NN are_VBP conditionally_RB independent_JJ given_VBN y._NN 214_CD So_RB ,_, a_DT training_NN set_NN is_VBZ a_DT random_JJ sample_NN from_IN a_DT distribution_NN p_NN -LRB-_-LRB- x_NN ,_, y_NN ,_, s_NNS -RRB-_-RRB- that_WDT satisfies_VBZ Equations_NNS -LRB-_-LRB- 1_LS -RRB-_-RRB- and_CC
