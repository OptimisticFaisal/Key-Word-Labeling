Sequential_JJ cost-sensitive_JJ decision_NN making_VBG with_IN reinforcement_NN learning_VBG
certain_JJ real-world_JJ applications_NNS like_IN targeted_VBN marketing_NN ._.
Function_NN approximation_NN amounts_VBZ to_TO representing_VBG the_DT value_NN function_NN as_IN some_DT reasonable_JJ function_NN of_IN state_NN features_NNS and_CC actions_NNS -LRB-_-LRB- see_VB ,_, for_IN example_NN ,_, =_JJ -_: =[_NN 3_CD ,_, 12_CD ,_, 14_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
The_DT usual_JJ online_JJ learning_NN approach_NN ,_, by_IN contrast_NN ,_, assigns_VBZ explicit_JJ values_NNS to_TO explicit_JJ state-action_JJ pairs_NNS ._.
For_IN targeted_VBN marketing_NN purposes_NNS ,_, the_DT state_NN features_NNS can_MD include_VB everything_NN that_WDT is_VBZ known_JJ abo_NN
certain_JJ real-world_JJ applications_NNS like_IN targeted_VBN marketing_NN ._.
Function_NN approximation_NN amounts_VBZ to_TO representing_VBG the_DT value_NN function_NN as_IN some_DT reasonable_JJ function_NN of_IN state_NN features_NNS and_CC actions_NNS -LRB-_-LRB- see_VB ,_, for_IN example_NN ,_, =_JJ -_: =[_NN 3_CD ,_, 12_CD ,_, 14_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
The_DT usual_JJ online_JJ learning_NN approach_NN ,_, by_IN contrast_NN ,_, assigns_VBZ explicit_JJ values_NNS to_TO explicit_JJ state-action_JJ pairs_NNS ._.
For_IN targeted_VBN marketing_NN purposes_NNS ,_, the_DT state_NN features_NNS can_MD include_VB everything_NN that_WDT is_VBZ known_JJ abo_NN
edly_RB runs_VBZ itself_PRP of_IN a_DT cliff_NN in_IN order_NN to_TO better_JJR estimate_NN the_DT exact_JJ shape_NN of_IN the_DT cliff_NN edge_NN in_IN an_DT attempt_NN to_TO find_VB the_DT best_JJS possible_JJ path_NN to_TO a_DT goal_NN state_NN ._.
Another_DT popular_JJ learning_NN method_NN ,_, known_VBN as_IN sarsa_NN =_JJ -_: =[_NN 10_CD -RRB-_-RRB- -_: =_JJ -_: ,_, is_VBZ less_RBR aggressive_JJ than_IN Q-learning_NN in_IN the_DT assumptions_NNS it_PRP makes_VBZ about_IN the_DT current_JJ knowledge_NN of_IN the_DT state_NN space_NN ._.
Like_IN Qlearning_NNP ,_, Sarsa-learning_JJ starts_NNS with_IN some_DT initial_JJ estimates_NNS for_IN the_DT Q-values_NNS that_WDT
f_LS Figure_NNP 2_CD ,_, Equation_NN 5_CD is_VBZ used_VBN ._.
2.3_CD Base_NN Regression_NN Method_NN :_: ProbE_VB As_IN the_DT base_NN learning_NN method_NN ,_, we_PRP employ_VBP the_DT multivariate_JJ linear-regression_NN tree_NN method_NN implemented_VBN in_IN the_DT IBM_NNP ProbE_NN data_NNS mining_NN engine_NN =_JJ -_: =[_NN 9_CD ,_, 1_CD -RRB-_-RRB- -_: =_SYM -_: ._.
This_DT learning_NN method_NN produces_VBZ decision_NN trees_NNS with_IN multivariate_JJ linear_JJ regression_NN models_NNS at_IN the_DT leaves_NNS ._.
Regression_NN models_NNS are_VBP constructed_VBN as_IN trees_NNS are_VBP built_VBN ,_, and_CC splits_VBZ are_VBP selected_VBN to_TO maximize_VB the_DT p_NN
st-sensitive_JJ learning_NN and_CC decision_NN making_NN ._.
Various_JJ authors_NNS have_VBP noted_VBN the_DT limitations_NNS of_IN classic_JJ supervised_JJ learning_NN methods_NNS when_WRB the_DT acquired_VBN rules_NNS are_VBP used_VBN for_IN cost-sensitive_JJ decision_NN making_NN -LRB-_-LRB- e.g._FW ,_, =_JJ -_: =[_NN 13_CD ,_, 4_CD ,_, 5_CD ,_, 17_CD ,_, 8_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
A_DT number_NN of_IN cost-sensitive_JJ learning_NN methods_NNS have_VBP been_VBN developed_VBN -LRB-_-LRB- 4_CD ,_, 17_CD ,_, 6_CD -RRB-_-RRB- that_WDT have_VBP been_VBN shown_VBN to_TO be_VB superior_JJ to_TO traditional_JJ classification-based_JJ methods_NNS ._.
However_RB ,_, these_DT cost-sensitive_JJ methods_NNS onl_VBP
s_NN of_IN classic_JJ supervised_JJ learning_NN methods_NNS when_WRB the_DT acquired_VBN rules_NNS are_VBP used_VBN for_IN cost-sensitive_JJ decision_NN making_NN -LRB-_-LRB- e.g._FW ,_, -LRB-_-LRB- 13_CD ,_, 4_CD ,_, 5_CD ,_, 17_CD ,_, 8_CD -RRB-_-RRB- -RRB-_-RRB- ._.
A_DT number_NN of_IN cost-sensitive_JJ learning_NN methods_NNS have_VBP been_VBN developed_VBN =_JJ -_: =[_NN 4_CD ,_, 17_CD ,_, 6_CD -RRB-_-RRB- -_: =_SYM -_: that_WDT have_VBP been_VBN shown_VBN to_TO be_VB superior_JJ to_TO traditional_JJ classification-based_JJ methods_NNS ._.
However_RB ,_, these_DT cost-sensitive_JJ methods_NNS only_RB try_VBP to_TO maximize_VB the_DT benefit_NN -LRB-_-LRB- equivalently_RB ,_, minimize_VBP the_DT cost_NN -RRB-_-RRB- of_IN a_DT single_JJ d_NN
ed_VBN in_IN the_DT introduction_NN ,_, we_PRP adopt_VBP the_DT popular_JJ Markov_NNP Decision_NN Process_VB -LRB-_-LRB- MDP_NN -RRB-_-RRB- model_NN in_IN reinforcement_NN learning_NN with_IN function_NN approximation_NN ._.
For_IN an_DT introduction_NN to_TO reinforcement_NN learning_NN see_VBP ,_, for_IN example_NN ,_, =_JJ -_: =[_NN 11_CD ,_, 7_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT following_NN is_VBZ a_DT brief_JJ description_NN of_IN an_DT MDP_NN ._.
At_IN any_DT point_NN in_IN time_NN ,_, the_DT environment_NN is_VBZ assumed_VBN to_TO be_VB in_IN one_CD of_IN a_DT set_NN of_IN possible_JJ states_NNS ._.
At_IN each_DT time_NN tick_VB -LRB-_-LRB- we_PRP assume_VBP a_DT discrete_JJ time_NN clock_NN -RRB-_-RRB- ,_, the_DT en_IN
st-sensitive_JJ learning_NN and_CC decision_NN making_NN ._.
Various_JJ authors_NNS have_VBP noted_VBN the_DT limitations_NNS of_IN classic_JJ supervised_JJ learning_NN methods_NNS when_WRB the_DT acquired_VBN rules_NNS are_VBP used_VBN for_IN cost-sensitive_JJ decision_NN making_NN -LRB-_-LRB- e.g._FW ,_, =_JJ -_: =[_NN 13_CD ,_, 4_CD ,_, 5_CD ,_, 17_CD ,_, 8_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
A_DT number_NN of_IN cost-sensitive_JJ learning_NN methods_NNS have_VBP been_VBN developed_VBN -LRB-_-LRB- 4_CD ,_, 17_CD ,_, 6_CD -RRB-_-RRB- that_WDT have_VBP been_VBN shown_VBN to_TO be_VB superior_JJ to_TO traditional_JJ classification-based_JJ methods_NNS ._.
However_RB ,_, these_DT cost-sensitive_JJ methods_NNS onl_VBP
-LRB-_-LRB- near_IN -RRB-_-RRB- optimum_JJ policy_NN over_IN time_NN through_IN observation_NN and_CC experimentation_NN ._.
Several_JJ approaches_NNS are_VBP known_VBN in_IN the_DT literature_NN ._.
One_CD popular_JJ reinforcement-learning_JJ method_NN known_VBN as_IN Q-learning_NN ,_, due_JJ to_TO Watkins_NNP =_SYM -_: =[_NN 15_CD -RRB-_-RRB- -_: =_JJ -_: ,_, is_VBZ based_VBN on_IN the_DT Bellman_NNP equation_NN -LRB-_-LRB- Equation_NN 3_CD -RRB-_-RRB- and_CC value_NN iteration_NN -LRB-_-LRB- Equation_NN 4_CD -RRB-_-RRB- ._.
Q-learning_NN estimates_VBZ optimum_JJ value_NN functions_NNS in_IN an_DT online_JJ fashion_NN when_WRB the_DT sets_NNS of_IN possible_JJ states_NNS and_CC actions_NNS are_VBP bot_NN
st-sensitive_JJ learning_NN and_CC decision_NN making_NN ._.
Various_JJ authors_NNS have_VBP noted_VBN the_DT limitations_NNS of_IN classic_JJ supervised_JJ learning_NN methods_NNS when_WRB the_DT acquired_VBN rules_NNS are_VBP used_VBN for_IN cost-sensitive_JJ decision_NN making_NN -LRB-_-LRB- e.g._FW ,_, =_JJ -_: =[_NN 13_CD ,_, 4_CD ,_, 5_CD ,_, 17_CD ,_, 8_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
A_DT number_NN of_IN cost-sensitive_JJ learning_NN methods_NNS have_VBP been_VBN developed_VBN -LRB-_-LRB- 4_CD ,_, 17_CD ,_, 6_CD -RRB-_-RRB- that_WDT have_VBP been_VBN shown_VBN to_TO be_VB superior_JJ to_TO traditional_JJ classification-based_JJ methods_NNS ._.
However_RB ,_, these_DT cost-sensitive_JJ methods_NNS onl_VBP
ed_VBN in_IN the_DT introduction_NN ,_, we_PRP adopt_VBP the_DT popular_JJ Markov_NNP Decision_NN Process_VB -LRB-_-LRB- MDP_NN -RRB-_-RRB- model_NN in_IN reinforcement_NN learning_NN with_IN function_NN approximation_NN ._.
For_IN an_DT introduction_NN to_TO reinforcement_NN learning_NN see_VBP ,_, for_IN example_NN ,_, =_JJ -_: =[_NN 11_CD ,_, 7_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT following_NN is_VBZ a_DT brief_JJ description_NN of_IN an_DT MDP_NN ._.
At_IN any_DT point_NN in_IN time_NN ,_, the_DT environment_NN is_VBZ assumed_VBN to_TO be_VB in_IN one_CD of_IN a_DT set_NN of_IN possible_JJ states_NNS ._.
At_IN each_DT time_NN tick_VB -LRB-_-LRB- we_PRP assume_VBP a_DT discrete_JJ time_NN clock_NN -RRB-_-RRB- ,_, the_DT en_IN
f_LS Figure_NNP 2_CD ,_, Equation_NN 5_CD is_VBZ used_VBN ._.
2.3_CD Base_NN Regression_NN Method_NN :_: ProbE_VB As_IN the_DT base_NN learning_NN method_NN ,_, we_PRP employ_VBP the_DT multivariate_JJ linear-regression_NN tree_NN method_NN implemented_VBN in_IN the_DT IBM_NNP ProbE_NN data_NNS mining_NN engine_NN =_JJ -_: =[_NN 9_CD ,_, 1_CD -RRB-_-RRB- -_: =_SYM -_: ._.
This_DT learning_NN method_NN produces_VBZ decision_NN trees_NNS with_IN multivariate_JJ linear_JJ regression_NN models_NNS at_IN the_DT leaves_NNS ._.
Regression_NN models_NNS are_VBP constructed_VBN as_IN trees_NNS are_VBP built_VBN ,_, and_CC splits_VBZ are_VBP selected_VBN to_TO maximize_VB the_DT p_NN
model_NN to_TO run_VB simulation_NN experiments_NNS for_IN evaluating_VBG the_DT acquired_VBN targeting_NN policy_NN ._.
3.1_CD Data_NNP Set_NNP The_NNP donation_NN data_NNS set_VBD we_PRP used_VBD from_IN the_DT KDD_NNP Cup_NNP 1998_CD competition_NN is_VBZ available_JJ from_IN the_DT UCI_NNP KDD_NNP repository_NN =_JJ -_: =[_NN 2_CD -RRB-_-RRB- -_: =_SYM -_: along_IN with_IN associated_VBN documentation_NN ._.
This_DT data_NN set_NN contains_VBZ information_NN concerning_VBG direct-mail_JJ promotions_NNS for_IN soliciting_VBG donations_NNS ._.
The_DT information_NN includes_VBZ demographic_JJ data_NNS as_RB well_RB as_IN promotion_NN hist_NN
st-sensitive_JJ learning_NN and_CC decision_NN making_NN ._.
Various_JJ authors_NNS have_VBP noted_VBN the_DT limitations_NNS of_IN classic_JJ supervised_JJ learning_NN methods_NNS when_WRB the_DT acquired_VBN rules_NNS are_VBP used_VBN for_IN cost-sensitive_JJ decision_NN making_NN -LRB-_-LRB- e.g._FW ,_, =_JJ -_: =[_NN 13_CD ,_, 4_CD ,_, 5_CD ,_, 17_CD ,_, 8_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
A_DT number_NN of_IN cost-sensitive_JJ learning_NN methods_NNS have_VBP been_VBN developed_VBN -LRB-_-LRB- 4_CD ,_, 17_CD ,_, 6_CD -RRB-_-RRB- that_WDT have_VBP been_VBN shown_VBN to_TO be_VB superior_JJ to_TO traditional_JJ classification-based_JJ methods_NNS ._.
However_RB ,_, these_DT cost-sensitive_JJ methods_NNS onl_VBP
st-sensitive_JJ learning_NN and_CC decision_NN making_NN ._.
Various_JJ authors_NNS have_VBP noted_VBN the_DT limitations_NNS of_IN classic_JJ supervised_JJ learning_NN methods_NNS when_WRB the_DT acquired_VBN rules_NNS are_VBP used_VBN for_IN cost-sensitive_JJ decision_NN making_NN -LRB-_-LRB- e.g._FW ,_, =_JJ -_: =[_NN 13_CD ,_, 4_CD ,_, 5_CD ,_, 17_CD ,_, 8_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
A_DT number_NN of_IN cost-sensitive_JJ learning_NN methods_NNS have_VBP been_VBN developed_VBN -LRB-_-LRB- 4_CD ,_, 17_CD ,_, 6_CD -RRB-_-RRB- that_WDT have_VBP been_VBN shown_VBN to_TO be_VB superior_JJ to_TO traditional_JJ classification-based_JJ methods_NNS ._.
However_RB ,_, these_DT cost-sensitive_JJ methods_NNS onl_VBP
