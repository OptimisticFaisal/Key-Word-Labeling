Time_NN and_CC sample_NN efficient_JJ discovery_NN of_IN Markov_NNP blankets_NNS and_CC direct_JJ causal_JJ relations_NNS
above_IN property_NN ,_, the_DT Markov_NNP Blanket_NNP is_VBZ inextricably_RB connected_VBN to_TO the_DT variable_JJ selection_NN problem_NN ,_, i.e._FW ,_, the_DT problem_NN of_IN choosing_VBG a_DT minimum_JJ set_NN of_IN predictors_NNS that_WDT optimally_RB classify_VBP T_NN ._.
In_IN particular_JJ ,_, in_IN =_JJ -_: =[_NN 10_CD -RRB-_-RRB- -_: =_JJ -_: we_PRP prove_VBP that_IN under_IN certain_JJ broad_JJ conditions_NNS the_DT Markov_NNP Blanket_NNP is_VBZ the_DT solution_NN to_TO the_DT variable_JJ selection_NN problem_NN ._.
Several_JJ algorithms_NNS are_VBP currently_RB available_JJ that_WDT can_MD induce_VB the_DT BN_NN that_WDT captures_VBZ the_DT
ests_NNS and_CC considering_VBG the_DT d-separation_NN relations_NNS they_PRP entail_VBP ,_, one_PRP can_MD reconstruct_VB the_DT BN_NN that_WDT captures_VBZ the_DT data_NNS generating_VBG process_NN ._.
This_DT is_VBZ the_DT main_JJ idea_NN behind_IN constraint-based_JJ BN_NN learning_NN approaches_VBZ =_JJ -_: =[_NN 8_CD ,_, 3_CD ,_, 5_CD -RRB-_-RRB- -_: =_SYM -_: ._.
The_DT following_VBG theorem_NN in_IN -LRB-_-LRB- 8_CD -RRB-_-RRB- is_VBZ foundational_JJ for_IN the_DT both_CC the_DT PC_NN and_CC the_DT MMPC_NNP algorithms_NNS of_IN Section_NN 3_CD :_: Theorem_NN 2_CD ._.
If_IN a_DT BN_NN N_NN is_VBZ faithful_JJ to_TO a_DT joint_JJ probability_NN distribution_NN J_NN then_RB :_: 1_CD ._.
There_EX is_VBZ an_DT edg_NN
iously_RB known_VBN algorithms_NNS for_IN inducing_VBG Markov_NNP Blankets_NNPS ,_, namely_RB the_DT Incremental_JJ Association_NN Markov_NN Blanket_NN -LRB-_-LRB- IAMB_NN -RRB-_-RRB- algorithm_NN -LRB-_-LRB- 11_CD -RRB-_-RRB- ,_, the_DT Grow-Shrink_NN -LRB-_-LRB- GS_NN -RRB-_-RRB- algorithm_NN -LRB-_-LRB- 5_CD -RRB-_-RRB- ,_, and_CC the_DT Koller-Sahami_NNP algorithm_NN -LRB-_-LRB- KS_NN -RRB-_-RRB- =_JJ -_: =[_NN 4_CD -RRB-_-RRB- -_: =_SYM -_: ._.
MMMB_NN trades-off_NN computation_NN time_NN for_IN required_VBN training_NN sample_NN size_NN ,_, while_IN still_RB being_VBG efficient_JJ enough_RB to_TO scale_VB up_RP to_TO thousands_NNS of_IN variables_NNS ._.
MMMB_NN yields_NNS up_IN to_TO exponential_JJ savings_NNS in_IN sample_NN relative_NN
smaller_JJR real_JJ BNs_NNS in_IN a_DT way_NN that_WDT retains_VBZ their_PRP$ structural_JJ and_CC probabilistic_JJ properties_NNS ,_, hoping_VBG that_IN the_DT simulated_JJ network_NN will_MD exhibit_VB the_DT same_JJ characteristics_NNS as_IN the_DT real_JJ BN_NN tiles_NNS -LRB-_-LRB- the_DT details_NNS are_VBP in_IN =_JJ -_: =[_NN 9_CD -RRB-_-RRB- -_: =--RRB-_NN ._.
More_RBR specifically_RB ,_, we_PRP randomly_RB generated_VBD ALARM-5K_NN by_IN tiling_VBG 135_CD copies_NNS of_IN ALARM_NN ._.
Similarly_RB ,_, for_IN Pigs-5K_NN -LRB-_-LRB- 11_CD copies_NNS of_IN original_JJ Pigs_NNS -RRB-_-RRB- and_CC Hailfinder5K_NN -LRB-_-LRB- 89_CD copies_NNS of_IN original_JJ Hailfinder_NN -RRB-_-RRB- ._.
We_PRP did_VBD not_RB
ales_NNS up_RB to_TO datasets_NNS with_IN thousands_NNS of_IN variables_NNS ._.
MMMB_NN is_VBZ compared_VBN with_IN all_DT previously_RB known_VBN algorithms_NNS for_IN inducing_VBG Markov_NNP Blankets_NNPS ,_, namely_RB the_DT Incremental_JJ Association_NN Markov_NN Blanket_NN -LRB-_-LRB- IAMB_NN -RRB-_-RRB- algorithm_NN =_JJ -_: =[_NN 11_CD -RRB-_-RRB- -_: =_JJ -_: ,_, the_DT Grow-Shrink_NN -LRB-_-LRB- GS_NN -RRB-_-RRB- algorithm_NN -LRB-_-LRB- 5_CD -RRB-_-RRB- ,_, and_CC the_DT Koller-Sahami_NNP algorithm_NN -LRB-_-LRB- KS_NN -RRB-_-RRB- -LRB-_-LRB- 4_CD -RRB-_-RRB- ._.
MMMB_NN trades-off_NN computation_NN time_NN for_IN required_VBN training_NN sample_NN size_NN ,_, while_IN still_RB being_VBG efficient_JJ enough_RB to_TO scale_VB up_RP to_TO th_DT
