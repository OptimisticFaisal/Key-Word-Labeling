An_DT iterative_JJ method_NN for_IN multi-class_JJ cost-sensitive_JJ learning_NN
h_NN in_IN cost-sensitive_JJ learning_NN falls_VBZ into_IN three_CD main_JJ categories_NNS ._.
The_DT first_JJ category_NN is_VBZ concerned_VBN with_IN making_VBG particular_JJ classifier_NN learners_NNS cost-sensitive_JJ ,_, including_VBG methods_NNS specific_JJ for_IN decision_NN trees_NNS =_JJ -_: =[_NN 14_CD ,_, 4_CD -RRB-_-RRB- -_: =_JJ -_: ,_, neural_JJ networks_NNS -LRB-_-LRB- 13_CD -RRB-_-RRB- and_CC support_NN vector_NN machines_NNS -LRB-_-LRB- 12_CD -RRB-_-RRB- ._.
The_DT second_JJ category_NN uses_VBZ Bayes_NNP risk_NN theory_NN to_TO assign_VB each_DT example_NN to_TO its_PRP$ lowest_JJS expected_VBN cost_NN class_NN -LRB-_-LRB- 8_CD ,_, 18_CD -RRB-_-RRB- ._.
This_DT requires_VBZ classifiers_NNS to_TO outpu_VB
earner_RB achieve_VB better_JJR weighted_JJ accuracy_NN than_IN that_DT attainable_JJ by_IN assigning_VBG all_DT examples_NNS to_TO the_DT negative_JJ class_NN ,_, as_IN we_PRP mentioned_VBD earlier_RBR ._.
4_LS ._.
EXPERIMENTAL_JJ EVALUATION_NN We_PRP use_VBP the_DT C4_NN .5_CD decision_NN tree_NN learner_NN =_JJ -_: =[_NN 17_CD -RRB-_-RRB- -_: =_SYM -_: as_IN the_DT base_NN classifier_NN learning_NN method_NN ,_, because_IN it_PRP is_VBZ a_DT standard_NN for_IN empirical_JJ comparisons_NNS and_CC it_PRP was_VBD used_VBN as_IN the_DT base_NN learner_NN by_IN Domingos_NNP for_IN the_DT MetaCost_NNP method_NN -LRB-_-LRB- 8_CD -RRB-_-RRB- ._.
We_PRP compare_VBP our_PRP$ methods_NNS against_IN
ing_NN falls_VBZ into_IN three_CD main_JJ categories_NNS ._.
The_DT first_JJ category_NN is_VBZ concerned_VBN with_IN making_VBG particular_JJ classifier_NN learners_NNS cost-sensitive_JJ ,_, including_VBG methods_NNS specific_JJ for_IN decision_NN trees_NNS -LRB-_-LRB- 14_CD ,_, 4_CD -RRB-_-RRB- ,_, neural_JJ networks_NNS =_JJ -_: =[_NN 13_CD -RRB-_-RRB- -_: =_JJ -_: and_CC support_NN vector_NN machines_NNS -LRB-_-LRB- 12_CD -RRB-_-RRB- ._.
The_DT second_JJ category_NN uses_VBZ Bayes_NNP risk_NN theory_NN to_TO assign_VB each_DT example_NN to_TO its_PRP$ lowest_JJS expected_VBN cost_NN class_NN -LRB-_-LRB- 8_CD ,_, 18_CD -RRB-_-RRB- ._.
This_DT requires_VBZ classifiers_NNS to_TO output_NN class_NN membership_NN pro_NN
d_NN ,_, because_IN it_PRP is_VBZ a_DT standard_NN for_IN empirical_JJ comparisons_NNS and_CC it_PRP was_VBD used_VBN as_IN the_DT base_NN learner_NN by_IN Domingos_NNP for_IN the_DT MetaCost_NNP method_NN -LRB-_-LRB- 8_CD -RRB-_-RRB- ._.
We_PRP compare_VBP our_PRP$ methods_NNS against_IN three_CD representative_JJ methods_NNS :_: Bagging_NN =_JJ -_: =[_NN 5_CD -RRB-_-RRB- -_: =_JJ -_: ,_, Averaging_VBG cost_NN -LRB-_-LRB- 7_CD ,_, 8_CD -RRB-_-RRB- and_CC MetaCost_NNP ._.
The_DT Averaging_VBG cost_NN method_NN was_VBD also_RB used_VBN for_IN comparison_NN in_IN -LRB-_-LRB- 8_CD -RRB-_-RRB- ._.
Note_VB that_IN Bagging_NNP is_VBZ a_DT cost-insensitive_JJ learning_NN method_NN ._.
Here_RB we_PRP give_VBP a_DT brief_JJ description_NN of_IN these_DT
e_LS ,_, we_PRP assumed_VBD that_IN the_DT hypotheses_NNS output_NN by_IN a_DT cost-sensitive_JJ learner_NN is_VBZ a_DT functional_JJ hypothesis_NN h_NN ,_, i.e._FW h_NN :_: X_NN !_.
Y_NN :_: It_PRP is_VBZ also_RB possible_JJ to_TO allow_VB hypotheses_NNS that_WDT are_VBP stochastic_JJ ,_, namely_RB h_NN :_: X_NN \_FW ThetasY_FW !_.
=_SYM -_: =[_NN 0_CD ;_: 1_LS -RRB-_-RRB- -_: =_JJ -_: subject_JJ to_TO the_DT stochastic_JJ condition_NN :_: 8x_NN 2_CD X_NN X_NN y2Y_NN h_NN -LRB-_-LRB- yjx_NN -RRB-_-RRB- =_JJ 1_CD :_: With_IN stochastic_JJ hypotheses_NNS ,_, stochastic_JJ cost-sensitive_JJ learning_NN is_VBZ defined_VBN as_IN the_DT process_NN of_IN finding_VBG a_DT hypothesis_NN minimizing_VBG the_DT following_VBG
