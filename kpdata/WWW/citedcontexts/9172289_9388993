t_NN the_DT learning_VBG black_JJ box_NN is_VBZ optimal_JJ on_IN each_DT bandit_NN problem_NN ._.
The_DT large_JJ literature_NN on_IN multi-armed_JJ bandit_NN optimization_NN is_VBZ relevant_JJ here_RB -LRB-_-LRB- 10_CD ,_, 4_CD ,_, 3_CD ,_, 7_CD -RRB-_-RRB- ,_, including_VBG some_DT directly_RB applied_VBN to_TO sponsored_VBN search_NN =_JJ -_: =[_NN 8_CD ,_, 11_CD ,_, 14_CD ,_, 6_CD -RRB-_-RRB- -_: =_SYM -_: ._.
Thus_RB far_RB we_PRP have_VBP described_VBN a_DT standard_JJ bandits_NN framework_NN ;_: we_PRP now_RB introduce_VBP outsourcing_NN ._.
We_PRP assume_VBP that_IN at_IN every_DT observation_NN of_IN any_DT keyphrase_FW i_FW ,_, the_DT agent_NN can_MD choose_VB to_TO forgo_VB the_DT opportunity_NN to_TO learn_VB
